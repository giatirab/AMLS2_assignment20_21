{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpadS-lmMGHz",
        "outputId": "e5a6b741-c081-4d8f-c617-97b30be9a855"
      },
      "source": [
        "!pip install ipdb\n",
        "!pip install --upgrade torchtext\n",
        "# This is a public repo\n",
        "!git clone https://github.com/giatirab/AMLS2_assignment20_21.git\n",
        "import os"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipdb in /usr/local/lib/python3.7/dist-packages (0.13.7)\n",
            "Requirement already satisfied: toml>=0.10.2; python_version > \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipdb) (0.10.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb) (54.2.0)\n",
            "Requirement already satisfied: ipython>=7.17.0; python_version > \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipdb) (7.22.0)\n",
            "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (3.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (5.0.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.18.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.17.0; python_version > \"3.6\"->ipdb) (0.8.2)\n",
            "Requirement already up-to-date: torchtext in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchtext) (3.7.4.3)\n",
            "Cloning into 'AMLS2_assignment20_21'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 91 (delta 2), reused 4 (delta 2), pack-reused 84\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPVzbZqyNxMT"
      },
      "source": [
        "project = \"AMLS2_assignment20_21\"\n",
        "os.chdir(project)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IECQngCSnrw",
        "outputId": "87878ec8-7561-4612-c64f-d09f888a770b"
      },
      "source": [
        "# check if GPU is active\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBiTN0BnM06H",
        "outputId": "ab4ef357-ad20-402d-9290-21a13f1ee2ea"
      },
      "source": [
        "!python main.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model parameters:\n",
            " {\n",
            "    \"batch_size\": 20,\n",
            "    \"block_dropout\": 0.2,\n",
            "    \"depth\": 3,\n",
            "    \"embedding_dim\": 128,\n",
            "    \"epochs\": 8,\n",
            "    \"gradient_clipping\": 1.0,\n",
            "    \"heads\": 3,\n",
            "    \"log_step\": 80000,\n",
            "    \"lr\": 0.0001,\n",
            "    \"lr_warmup\": 10,\n",
            "    \"max_tweet_len\": 119,\n",
            "    \"model_name\": \"\",\n",
            "    \"output_dropout\": 0.1,\n",
            "    \"test_batch_size\": 1000\n",
            "}\n",
            "2021-04-18 13:28:05.990080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Num labels: 2\n",
            "Vocab size: 19982\n",
            "Loaded pretrained model: models/ca8538c49a089d19f6d40cc6178f1e0c\n",
            "Preprocessing started\n",
            "100% 1440000/1440000 [24:12<00:00, 991.61it/s]\n",
            "100% 159999/159999 [02:47<00:00, 957.20it/s]\n",
            "Tokenization complete\n",
            "100% 1440000/1440000 [00:05<00:00, 268346.56it/s]\n",
            "100% 159999/159999 [00:00<00:00, 234163.48it/s]\n",
            "Extracted simplified tweets, saving...\n",
            "tcmalloc: large alloc 1440006144 bytes == 0x560ed83bc000 @  0x7f2678f19001 0x7f2624d4954f 0x7f2624d99b58 0x7f2624d9ce83 0x7f2624d9d07b 0x7f2624e3e761 0x560e663f10e4 0x560e663f0de0 0x560e664656f5 0x560e6645fb0e 0x560e663f277a 0x560e6646186a 0x560e6645fb0e 0x560e663f277a 0x560e66464e50 0x560e6645fe0d 0x560e663f277a 0x560e66464e50 0x560e663f269a 0x560e66464e50 0x560e663f472b 0x560e664355e9 0x560e664356f6 0x560e664616d6 0x560e6645fb0e 0x560e663f277a 0x560e6646186a 0x560e6645fe0d 0x560e663f277a 0x560e66460c9e 0x560e663f269a\n",
            "Generating vocabulary\n",
            "Computing max length\n",
            "Saving fields and parameters\n",
            "Compressing CSVs\n",
            "Preprocessing concluded\n",
            "Uncompressing data\n",
            "Uncompressing data\n",
            "Extracting datasets\n",
            "Creating batch iterators\n",
            "AvgRec: 0.6782,\tavg loss: 0.000719,\tepoch: 0\n",
            "\n",
            "  6% 3994/64800 [01:13<17:46, 57.02it/s]Train loss: 0.027679\tEpoch: 0\n",
            " 12% 7995/64800 [02:24<16:31, 57.26it/s]Train loss: 0.026202\tEpoch: 0\n",
            " 19% 11999/64800 [03:35<15:16, 57.58it/s]Train loss: 0.025496\tEpoch: 0\n",
            " 25% 15998/64800 [04:46<14:37, 55.61it/s]Train loss: 0.025225\tEpoch: 0\n",
            " 31% 19995/64800 [05:57<13:18, 56.14it/s]Train loss: 0.024794\tEpoch: 0\n",
            " 37% 23996/64800 [07:08<12:12, 55.72it/s]Train loss: 0.024269\tEpoch: 0\n",
            " 43% 27999/64800 [08:20<10:34, 57.97it/s]Train loss: 0.024108\tEpoch: 0\n",
            " 49% 31999/64800 [09:31<09:32, 57.34it/s]Train loss: 0.023909\tEpoch: 0\n",
            " 56% 35995/64800 [10:42<08:39, 55.42it/s]Train loss: 0.023535\tEpoch: 0\n",
            " 62% 39996/64800 [11:54<07:17, 56.72it/s]Train loss: 0.023363\tEpoch: 0\n",
            " 68% 43995/64800 [13:05<06:05, 56.89it/s]Train loss: 0.023259\tEpoch: 0\n",
            " 74% 47998/64800 [14:17<04:58, 56.20it/s]Train loss: 0.023113\tEpoch: 0\n",
            " 80% 51994/64800 [15:29<03:48, 56.04it/s]Train loss: 0.022907\tEpoch: 0\n",
            " 86% 55995/64800 [16:40<02:33, 57.33it/s]Train loss: 0.022775\tEpoch: 0\n",
            " 93% 59997/64800 [17:52<01:25, 56.00it/s]Train loss: 0.022595\tEpoch: 0\n",
            " 99% 63994/64800 [19:03<00:14, 56.33it/s]Train loss: 0.022572\tEpoch: 0\n",
            "100% 64800/64800 [19:18<00:00, 55.95it/s]\n",
            "Train avg loss: 0.023815\n",
            "AvgRec: 0.7954,\tavg loss: 0.000463,\tepoch: 0\n",
            "\n",
            "  6% 3996/64800 [01:13<17:58, 56.36it/s]Train loss: 0.026731\tEpoch: 1\n",
            " 12% 7995/64800 [02:25<16:42, 56.66it/s]Train loss: 0.022231\tEpoch: 1\n",
            " 19% 11997/64800 [03:36<15:18, 57.50it/s]Train loss: 0.022024\tEpoch: 1\n",
            " 25% 15998/64800 [04:47<15:09, 53.66it/s]Train loss: 0.022142\tEpoch: 1\n",
            " 31% 19994/64800 [05:59<13:21, 55.93it/s]Train loss: 0.021941\tEpoch: 1\n",
            " 37% 23999/64800 [07:10<12:24, 54.84it/s]Train loss: 0.021849\tEpoch: 1\n",
            " 43% 27996/64800 [08:22<10:54, 56.26it/s]Train loss: 0.021809\tEpoch: 1\n",
            " 49% 31997/64800 [09:33<09:35, 56.99it/s]Train loss: 0.021739\tEpoch: 1\n",
            " 56% 35997/64800 [10:44<08:37, 55.68it/s]Train loss: 0.021762\tEpoch: 1\n",
            " 62% 39996/64800 [11:56<07:31, 54.97it/s]Train loss: 0.021548\tEpoch: 1\n",
            " 68% 43997/64800 [13:07<06:05, 56.92it/s]Train loss: 0.021512\tEpoch: 1\n",
            " 74% 47996/64800 [14:19<04:48, 58.17it/s]Train loss: 0.021604\tEpoch: 1\n",
            " 80% 51996/64800 [15:30<03:51, 55.26it/s]Train loss: 0.021553\tEpoch: 1\n",
            " 86% 55996/64800 [16:41<02:35, 56.52it/s]Train loss: 0.021409\tEpoch: 1\n",
            " 93% 59994/64800 [17:52<01:26, 55.54it/s]Train loss: 0.021423\tEpoch: 1\n",
            " 99% 63996/64800 [19:03<00:14, 55.86it/s]Train loss: 0.02123\tEpoch: 1\n",
            "100% 64800/64800 [19:17<00:00, 55.96it/s]\n",
            "Train avg loss: 0.02176\n",
            "AvgRec: 0.8037,\tavg loss: 0.000443,\tepoch: 1\n",
            "\n",
            "  6% 3999/64800 [01:13<17:34, 57.66it/s]Train loss: 0.025663\tEpoch: 2\n",
            " 12% 7999/64800 [02:23<16:37, 56.97it/s]Train loss: 0.021083\tEpoch: 2\n",
            " 19% 11996/64800 [03:34<15:20, 57.38it/s]Train loss: 0.021032\tEpoch: 2\n",
            " 25% 15999/64800 [04:45<14:33, 55.87it/s]Train loss: 0.020836\tEpoch: 2\n",
            " 31% 19999/64800 [05:56<12:56, 57.72it/s]Train loss: 0.020836\tEpoch: 2\n",
            " 37% 23996/64800 [07:06<12:27, 54.59it/s]Train loss: 0.020887\tEpoch: 2\n",
            " 43% 27998/64800 [08:18<10:44, 57.09it/s]Train loss: 0.020733\tEpoch: 2\n",
            " 49% 31997/64800 [09:29<09:54, 55.17it/s]Train loss: 0.020787\tEpoch: 2\n",
            " 56% 35997/64800 [10:40<08:17, 57.88it/s]Train loss: 0.020783\tEpoch: 2\n",
            " 62% 39999/64800 [11:50<07:14, 57.08it/s]Train loss: 0.021014\tEpoch: 2\n",
            " 68% 43994/64800 [13:01<05:57, 58.22it/s]Train loss: 0.020782\tEpoch: 2\n",
            " 74% 47997/64800 [14:12<05:01, 55.66it/s]Train loss: 0.020814\tEpoch: 2\n",
            " 80% 51995/64800 [15:22<03:52, 54.98it/s]Train loss: 0.020969\tEpoch: 2\n",
            " 86% 55997/64800 [16:33<02:29, 58.69it/s]Train loss: 0.020633\tEpoch: 2\n",
            " 93% 59995/64800 [17:44<01:25, 56.41it/s]Train loss: 0.020498\tEpoch: 2\n",
            " 99% 63999/64800 [18:55<00:14, 56.21it/s]Train loss: 0.020646\tEpoch: 2\n",
            "100% 64800/64800 [19:09<00:00, 56.36it/s]\n",
            "Train avg loss: 0.020864\n",
            "AvgRec: 0.8145,\tavg loss: 0.000442,\tepoch: 2\n",
            "\n",
            "  6% 3994/64800 [01:13<18:07, 55.90it/s]Train loss: 0.024525\tEpoch: 3\n",
            " 12% 7994/64800 [02:24<16:59, 55.70it/s]Train loss: 0.020341\tEpoch: 3\n",
            " 19% 11998/64800 [03:35<16:12, 54.31it/s]Train loss: 0.020657\tEpoch: 3\n",
            " 25% 15997/64800 [04:47<14:22, 56.57it/s]Train loss: 0.02023\tEpoch: 3\n",
            " 31% 19994/64800 [05:58<13:28, 55.39it/s]Train loss: 0.020306\tEpoch: 3\n",
            " 37% 23998/64800 [07:10<12:33, 54.12it/s]Train loss: 0.020457\tEpoch: 3\n",
            " 43% 27995/64800 [08:21<10:38, 57.64it/s]Train loss: 0.020355\tEpoch: 3\n",
            " 49% 31997/64800 [09:31<10:00, 54.67it/s]Train loss: 0.020396\tEpoch: 3\n",
            " 56% 35995/64800 [10:42<08:34, 55.99it/s]Train loss: 0.020348\tEpoch: 3\n",
            " 62% 39996/64800 [11:53<07:13, 57.16it/s]Train loss: 0.02007\tEpoch: 3\n",
            " 68% 43999/64800 [13:04<06:07, 56.54it/s]Train loss: 0.020311\tEpoch: 3\n",
            " 74% 47994/64800 [14:14<04:55, 56.93it/s]Train loss: 0.020088\tEpoch: 3\n",
            " 80% 51994/64800 [15:25<03:53, 54.95it/s]Train loss: 0.020316\tEpoch: 3\n",
            " 86% 55997/64800 [16:35<02:40, 55.01it/s]Train loss: 0.019983\tEpoch: 3\n",
            " 93% 59997/64800 [17:46<01:23, 57.19it/s]Train loss: 0.020248\tEpoch: 3\n",
            " 99% 63999/64800 [18:56<00:13, 59.22it/s]Train loss: 0.020338\tEpoch: 3\n",
            "100% 64800/64800 [19:11<00:00, 56.29it/s]\n",
            "Train avg loss: 0.020307\n",
            "AvgRec: 0.8195,\tavg loss: 0.000433,\tepoch: 3\n",
            "\n",
            "  6% 3993/64800 [01:13<17:40, 57.33it/s]Train loss: 0.024049\tEpoch: 4\n",
            " 12% 7997/64800 [02:23<16:21, 57.87it/s]Train loss: 0.019957\tEpoch: 4\n",
            " 19% 11997/64800 [03:34<15:24, 57.12it/s]Train loss: 0.019924\tEpoch: 4\n",
            " 25% 15996/64800 [04:44<13:57, 58.25it/s]Train loss: 0.019978\tEpoch: 4\n",
            " 31% 19998/64800 [05:55<13:31, 55.23it/s]Train loss: 0.019862\tEpoch: 4\n",
            " 37% 23996/64800 [07:05<11:58, 56.81it/s]Train loss: 0.019889\tEpoch: 4\n",
            " 43% 27998/64800 [08:16<11:18, 54.24it/s]Train loss: 0.019937\tEpoch: 4\n",
            " 49% 31996/64800 [09:26<09:43, 56.25it/s]Train loss: 0.020104\tEpoch: 4\n",
            " 56% 35996/64800 [10:37<08:46, 54.72it/s]Train loss: 0.019894\tEpoch: 4\n",
            " 62% 39999/64800 [11:47<07:21, 56.16it/s]Train loss: 0.019812\tEpoch: 4\n",
            " 68% 43997/64800 [12:58<06:14, 55.48it/s]Train loss: 0.019964\tEpoch: 4\n",
            " 74% 47994/64800 [14:08<04:53, 57.18it/s]Train loss: 0.019908\tEpoch: 4\n",
            " 80% 51994/64800 [15:19<03:44, 57.13it/s]Train loss: 0.019631\tEpoch: 4\n",
            " 86% 55994/64800 [16:30<02:45, 53.32it/s]Train loss: 0.019778\tEpoch: 4\n",
            " 93% 59993/64800 [17:40<01:25, 56.49it/s]Train loss: 0.019928\tEpoch: 4\n",
            " 99% 63998/64800 [18:50<00:14, 56.29it/s]Train loss: 0.019906\tEpoch: 4\n",
            "100% 64800/64800 [19:05<00:00, 56.59it/s]\n",
            "Train avg loss: 0.019909\n",
            "AvgRec: 0.8216,\tavg loss: 0.000432,\tepoch: 4\n",
            "\n",
            "  6% 3995/64800 [01:12<18:13, 55.60it/s]Train loss: 0.023685\tEpoch: 5\n",
            " 12% 7998/64800 [02:24<17:39, 53.60it/s]Train loss: 0.019495\tEpoch: 5\n",
            " 19% 11998/64800 [03:35<16:15, 54.12it/s]Train loss: 0.019692\tEpoch: 5\n",
            " 25% 15997/64800 [04:45<14:06, 57.68it/s]Train loss: 0.019654\tEpoch: 5\n",
            " 31% 19996/64800 [05:56<13:05, 57.07it/s]Train loss: 0.019626\tEpoch: 5\n",
            " 37% 23995/64800 [07:07<12:21, 55.05it/s]Train loss: 0.019449\tEpoch: 5\n",
            " 43% 27998/64800 [08:18<10:39, 57.58it/s]Train loss: 0.019489\tEpoch: 5\n",
            " 49% 31996/64800 [09:28<09:38, 56.74it/s]Train loss: 0.019701\tEpoch: 5\n",
            " 56% 35996/64800 [10:39<08:56, 53.72it/s]Train loss: 0.019447\tEpoch: 5\n",
            " 62% 39995/64800 [11:51<07:14, 57.14it/s]Train loss: 0.01959\tEpoch: 5\n",
            " 68% 43995/64800 [13:01<06:02, 57.38it/s]Train loss: 0.019491\tEpoch: 5\n",
            " 74% 47994/64800 [14:12<04:52, 57.54it/s]Train loss: 0.019496\tEpoch: 5\n",
            " 80% 51999/64800 [15:22<03:49, 55.85it/s]Train loss: 0.019583\tEpoch: 5\n",
            " 86% 55996/64800 [16:33<02:35, 56.69it/s]Train loss: 0.01959\tEpoch: 5\n",
            " 93% 59995/64800 [17:43<01:24, 56.84it/s]Train loss: 0.019637\tEpoch: 5\n",
            " 99% 63997/64800 [18:54<00:13, 57.73it/s]Train loss: 0.019805\tEpoch: 5\n",
            "100% 64800/64800 [19:08<00:00, 56.43it/s]\n",
            "Train avg loss: 0.019594\n",
            "AvgRec: 0.8171,\tavg loss: 0.00043,\tepoch: 5\n",
            "\n",
            "  6% 3996/64800 [01:12<18:06, 55.96it/s]Train loss: 0.023078\tEpoch: 6\n",
            " 12% 7999/64800 [02:23<16:16, 58.18it/s]Train loss: 0.01926\tEpoch: 6\n",
            " 19% 11997/64800 [03:33<15:51, 55.49it/s]Train loss: 0.019276\tEpoch: 6\n",
            " 25% 15995/64800 [04:44<14:53, 54.64it/s]Train loss: 0.019341\tEpoch: 6\n",
            " 31% 19999/64800 [05:55<13:23, 55.73it/s]Train loss: 0.019482\tEpoch: 6\n",
            " 37% 23995/64800 [07:06<12:02, 56.48it/s]Train loss: 0.019481\tEpoch: 6\n",
            " 43% 27999/64800 [08:17<10:36, 57.81it/s]Train loss: 0.01944\tEpoch: 6\n",
            " 49% 31995/64800 [09:28<09:24, 58.15it/s]Train loss: 0.019274\tEpoch: 6\n",
            " 56% 35999/64800 [10:38<08:26, 56.90it/s]Train loss: 0.019389\tEpoch: 6\n",
            " 62% 39997/64800 [11:49<07:08, 57.86it/s]Train loss: 0.01942\tEpoch: 6\n",
            " 68% 43997/64800 [13:00<06:04, 57.14it/s]Train loss: 0.019296\tEpoch: 6\n",
            " 74% 47996/64800 [14:11<05:06, 54.75it/s]Train loss: 0.019238\tEpoch: 6\n",
            " 80% 51995/64800 [15:23<03:52, 55.10it/s]Train loss: 0.019339\tEpoch: 6\n",
            " 86% 55999/64800 [16:34<02:42, 54.19it/s]Train loss: 0.019482\tEpoch: 6\n",
            " 93% 59996/64800 [17:45<01:27, 54.99it/s]Train loss: 0.019531\tEpoch: 6\n",
            " 99% 63995/64800 [18:55<00:13, 58.00it/s]Train loss: 0.019148\tEpoch: 6\n",
            "100% 64800/64800 [19:09<00:00, 56.35it/s]\n",
            "Train avg loss: 0.01935\n",
            "AvgRec: 0.8256,\tavg loss: 0.000447,\tepoch: 6\n",
            "\n",
            "  6% 3996/64800 [01:11<17:29, 57.96it/s]Train loss: 0.022974\tEpoch: 7\n",
            " 12% 7998/64800 [02:20<16:29, 57.41it/s]Train loss: 0.018925\tEpoch: 7\n",
            " 19% 11993/64800 [03:29<15:01, 58.59it/s]Train loss: 0.019212\tEpoch: 7\n",
            " 25% 15997/64800 [04:38<14:02, 57.91it/s]Train loss: 0.019103\tEpoch: 7\n",
            " 31% 19995/64800 [05:47<12:34, 59.41it/s]Train loss: 0.019009\tEpoch: 7\n",
            " 37% 23995/64800 [06:57<11:47, 57.70it/s]Train loss: 0.019026\tEpoch: 7\n",
            " 43% 27997/64800 [08:09<10:40, 57.44it/s]Train loss: 0.019172\tEpoch: 7\n",
            " 49% 31997/64800 [09:19<09:39, 56.57it/s]Train loss: 0.019054\tEpoch: 7\n",
            " 56% 35995/64800 [10:30<08:22, 57.35it/s]Train loss: 0.019092\tEpoch: 7\n",
            " 62% 39999/64800 [11:41<07:43, 53.55it/s]Train loss: 0.019195\tEpoch: 7\n",
            " 68% 43994/64800 [12:52<06:34, 52.76it/s]Train loss: 0.01914\tEpoch: 7\n",
            " 74% 47996/64800 [14:03<05:00, 55.87it/s]Train loss: 0.019141\tEpoch: 7\n",
            " 80% 51998/64800 [15:15<03:47, 56.30it/s]Train loss: 0.019239\tEpoch: 7\n",
            " 86% 55997/64800 [16:26<02:34, 56.97it/s]Train loss: 0.019188\tEpoch: 7\n",
            " 93% 59997/64800 [17:37<01:23, 57.38it/s]Train loss: 0.01904\tEpoch: 7\n",
            " 99% 63998/64800 [18:49<00:14, 55.69it/s]Train loss: 0.019234\tEpoch: 7\n",
            "100% 64800/64800 [19:03<00:00, 56.65it/s]\n",
            "Train avg loss: 0.01912\n",
            "AvgRec: 0.8269,\tavg loss: 0.000475,\tepoch: 7\n",
            "\n",
            "Performing final test\n",
            "AvgRec: 0.8263,\tavg loss: 0.000478,\tepoch: 7\n",
            "\n",
            "Best val AvgRec:0.827 at epoch:8\n",
            "\n",
            "thought sleeping in was an option tomorrow but realizing that it now is not. evaluations in the morning and work in the afternoon!\n",
            "Unknown words: ['evaluations']\n",
            "Confidence: 97.4%\n",
            "negative \n",
            "\n",
            "I hate everything and the world sucks\n",
            "Confidence: 99.2%\n",
            "negative \n",
            "\n",
            "I love you and the world is beautiful\n",
            "Confidence: 98.8%\n",
            "positive \n",
            "\n",
            "I fell in love with you\n",
            "Confidence: 92.2%\n",
            "negative \n",
            "\n",
            "Do you want to merry me?\n",
            "Confidence: 75.4%\n",
            "positive \n",
            "\n",
            "I'll kick your ass\n",
            "Confidence: 98.7%\n",
            "positive \n",
            "\n",
            "This water is tasty\n",
            "Confidence: 98.2%\n",
            "positive \n",
            "\n",
            "This food is amazing\n",
            "Confidence: 98.6%\n",
            "positive \n",
            "\n",
            "When I'm with you I feel like I'm complete.\n",
            "Confidence: 90.8%\n",
            "positive \n",
            "\n",
            "Studying all day makes me deeply satisfied\n",
            "Confidence: 94.6%\n",
            "negative \n",
            "\n",
            "I can't stand you any more, we better not see each others again.\n",
            "Confidence: 92.1%\n",
            "negative \n",
            "\n",
            "I think I like you\n",
            "Confidence: 98.3%\n",
            "positive \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z_j6bDmm2Zx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}